{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de96343e-2ff8-4c10-a3d3-39665462754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import models.mapping\n",
    "import utils\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0024f95d-ae38-4ab1-9768-2cef0a885f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "patch_size = 384\n",
    "batch_size = 8\n",
    "keys = [\"optical\", \"dem\"]\n",
    "n_outputs = 2\n",
    "\n",
    "# Adjust model name to match with the intended model\n",
    "model_name = \"glavitu_regionencoding\"\n",
    "\n",
    "eps_diff = 1e-8\n",
    "epochs_tolerance = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67edd0d-7b4c-4395-9b9b-3d66cdae490a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b295800f-9639-41e1-9ad7-d590b090e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the builder parameters manually if needed\n",
    "model_builder = models.mapping.GlaViTU\n",
    "model_args = {\n",
    "    \"input_shapes\": {\n",
    "        \"optical\": (patch_size, patch_size, 6),\n",
    "        \"dem\": (patch_size, patch_size, 2),\n",
    "    }, \n",
    "    \"n_outputs\": n_outputs, \n",
    "    \"use_location\": True,\n",
    "    \"location_size\": 12,\n",
    "    \"dropout\": 0.10, \n",
    "    \"inference_dropout\": False,\n",
    "    \"use_deepsupervision\": True,\n",
    "    \"name\": model_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf59774-ef1b-4467-92c4-ea28a697f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 11:57:41.674658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:41.711696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:41.711888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:41.712475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 11:57:41.713176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:41.713329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:41.713455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:42.231202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:42.231395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:42.231535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-08 11:57:42.231647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22261 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "weights_path = os.path.join(\"weights\", f\"{model_name}_weights.h5\")\n",
    "model = utils.build_model(\n",
    "    model_builder, model_args,\n",
    "    weights_path=weights_path, mode=\"testing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097f7f6d-b3cb-463c-87e6-7a71bb45151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"glavitu_regionencoding\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " location (InputLayer)          [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " optical (InputLayer)           [(None, 384, 384, 6  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " dem (InputLayer)               [(None, 384, 384, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " location_encoding_block (Locat  (None, 64)          5504        ['location[0][0]']               \n",
      " ionEncodingBlock)                                                                                \n",
      "                                                                                                  \n",
      " fusion_block (FusionBlock)     (None, 384, 384, 64  96256       ['optical[0][0]',                \n",
      "                                )                                 'dem[0][0]']                    \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 1, 1, 64)     0           ['location_encoding_block[0][0]']\n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)       (None, 384, 384, 64  0           ['fusion_block[0][0]',           \n",
      "                                )                                 'tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " SETR (Functional)              (None, 384, 384, 64  1838208     ['tf.math.add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 384, 384, 64  0           ['SETR[0][0]',                   \n",
      "                                )                                 'tf.math.add[0][0]']            \n",
      "                                                                                                  \n",
      " ResUNet (Functional)           (None, 384, 384, 64  8097344     ['add_12[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 384, 384, 64  0           ['add_12[0][0]',                 \n",
      "                                )                                 'ResUNet[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 384, 384, 2)  130         ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,037,442\n",
      "Trainable params: 10,029,634\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8432e-6b45-419b-b3f4-c31f2379f71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1412fa-d9ef-4971-a8d0-a4101d9ad39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the .pickle with the features\n",
    "features_path = os.path.join(\"/path\", \"to\", \"file.pickle\")\n",
    "with open(features_path, \"rb\") as file:\n",
    "    features, attrs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baaa72c-e619-4021-9e59-a6e21a5fd46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d65bc3-5b2e-4d8d-abdd-9ca481fead00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_per_epoch = int(attrs[\"height\"] * attrs[\"width\"] / patch_size**2 / batch_size + 0.5)\n",
    "batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8688cfd-1e8d-4130-8910-cc4c92173a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd5479df-ca20-4dca-b296-7b659afca283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataGenerator(features, attrs, keys=keys, patch_size=patch_size, batch_size=batch_size):\n",
    "    while True:\n",
    "        batch = {key: [] for key in keys}\n",
    "        height, width = attrs[\"height\"],  attrs[\"width\"]\n",
    "        pad_height, pad_width = attrs[\"pad_height\"], attrs[\"pad_width\"]\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            row = np.random.choice(height - patch_size) + pad_height\n",
    "            col = np.random.choice(width - patch_size) + pad_width\n",
    "            row_slice = slice(row, row + patch_size)\n",
    "            col_slice = slice(col, col + patch_size)\n",
    "            for key in keys:\n",
    "                patch = features[key][row_slice, col_slice, :]\n",
    "                batch[key].append(patch)\n",
    "\n",
    "        batch = {key: np.array(value) for key, value in batch.items()}\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d39bf271-a280-4cb3-b88d-e80ccd546390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(features, attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49910fca-0b90-490d-a5a0-8c6658e9090c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c343d22-6f7b-4772-8b6e-557d61c1cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(probs, eps=1e-6, C=float(n_outputs)):\n",
    "    entropy = -tf.reduce_sum(probs * tf.math.log(probs + eps) / tf.math.log(C), axis=-1)\n",
    "    return tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b90f1c2d-e112-4f2a-9279-b36eff1e78db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(12,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimised_bias = tf.Variable(tf.ones((12,)), trainable=True, dtype=tf.float32)\n",
    "optimised_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8505d837-1f68-4115-9898-f4a6a378a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c73fd74c-7239-4378-8a9c-5db8a7213289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/100 [00:00<?, ?it/s]2024-02-08 11:58:49.025071: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-02-08 11:58:49.687585: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-02-08 11:58:50.668475: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-08 11:58:50.669062: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-08 11:58:50.669087: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-08 11:58:50.669689: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-08 11:58:50.669756: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "100%|███████████████████████████████████████████████████████████████| 100/100 [23:09<00:00, 13.89s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs_with_eps_steps = 0\n",
    "\n",
    "for _ in tqdm(range(epochs)):\n",
    "    prev_bias = tf.Variable(optimised_bias)\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        batch = data_generator.__next__()\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(optimised_bias)\n",
    "            softmax_bias = tf.nn.softmax(optimised_bias)\n",
    "            softmax_bias = tf.tile(tf.expand_dims(softmax_bias, axis=0), [batch_size, 1])\n",
    "            batch[\"location\"] = softmax_bias\n",
    "            output = model(batch)\n",
    "            loss = shannon_entropy(output)\n",
    "        grads = tape.gradient(loss, [optimised_bias])\n",
    "        optimizer.apply_gradients(zip(grads, [optimised_bias]))\n",
    "        \n",
    "    diff = tf.reduce_sum((optimised_bias - prev_bias) ** 2)\n",
    "    if diff < eps_diff:\n",
    "        epochs_with_eps_steps += 1\n",
    "    else: \n",
    "        epochs_with_eps_steps = 0\n",
    "        \n",
    "    if epochs_with_eps_steps >= epochs_tolerance:\n",
    "        print(f\"{epochs_tolerance} with the bias difference less than {eps_diff}, early stopping.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be34b0f-60c0-4e82-83fc-e5c9a3506ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa7aabe-39e9-4cb4-9166-c5b00cfcdbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10099009, 0.06659123, 0.06655549, 0.07377534, 0.10282184,\n",
       "       0.0664518 , 0.10387994, 0.06812785, 0.10622469, 0.10675227,\n",
       "       0.0704275 , 0.067402  ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_vector = np.array(tf.nn.softmax(optimised_bias))\n",
    "region_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3695e829-f189-4b1d-bca9-d3ed1a8e9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the path where to save the optimised region vector to \n",
    "with open(\"region_vector.pickle\", \"wb\") as dst:\n",
    "    pickle.dump(region_vector, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8d3c5-2f4d-41dd-89f3-408219d0a765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
